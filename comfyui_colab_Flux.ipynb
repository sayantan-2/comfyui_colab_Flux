{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayantan-2/comfyui_colab_Flux/blob/main/comfyui_colab_Flux.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "Git clone the [ComfyUI](https://github.com/comfyanonymous/ComfyUI) repo and install the requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bbbbbbbbbb"
      },
      "outputs": [],
      "source": [
        "!git clone -q https://github.com/comfyanonymous/ComfyUI\n",
        "%pip install -q xformers!=0.0.18 -r /content/ComfyUI/requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some Helpful Custom Nodes\n",
        "!git clone -q https://github.com/ltdrdata/ComfyUI-Manager /content/ComfyUI/custom_nodes/comfyui-manager\n",
        "\n",
        "!git clone -q https://github.com/ClownsharkBatwing/RES4LYF.git /content/ComfyUI/custom_nodes/RES4LYF\n",
        "!git clone -q https://github.com/rgthree/rgthree-comfy.git /content/ComfyUI/custom_nodes/rgthree-comfy\n",
        "!git clone -q https://github.com/yolain/ComfyUI-Easy-Use.git /content/ComfyUI/custom_nodes/ComfyUI-Easy-Use"
      ],
      "metadata": {
        "id": "0a9tsc6ym4F6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccccccccc"
      },
      "source": [
        "Download the vae and dual text encoder needed for FLUX - (Compulsory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qb9xz1ViENoO"
      },
      "outputs": [],
      "source": [
        "!wget -q --show-progress https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors -P /content/ComfyUI/models/text_encoders/\n",
        "!wget -q --show-progress https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors -P /content/ComfyUI/models/text_encoders/\n",
        "!wget -q --show-progress https://huggingface.co/cocktailpeanut/xulf-dev/resolve/main/ae.safetensors -P /content/ComfyUI/models/vae/\n",
        "\n",
        "# 8-step distilled lora for fast inference on dev models\n",
        "# !wget -q --show-progress https://huggingface.co/alimama-creative/FLUX.1-Turbo-Alpha/resolve/main/diffusion_pytorch_model.safetensors -P /content/ComfyUI/models/loras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWglWy21uVpP"
      },
      "source": [
        "\n",
        "The **FP8 version** runs smoothly on the free tier (without LoRA), but if you want to use it with a LoRA, it requires more resources than the free Colab tier provides.  \n",
        "In that case, you can opt for the [gguf](https://huggingface.co/collections/QuantStack/flux-ggufs-68264cfc663d50c418940b30) quantized versions or the [Nunchaku](https://huggingface.co/nunchaku-tech/models) versions instead.\n",
        "\n",
        ">**Note** : You need only one , either a gguf quantized model (under 10GB) or the Nunchanku model\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option 1 : fp8 quantized - from [Comfy-Org](https://huggingface.co/Comfy-Org/flux1-dev/tree/main)"
      ],
      "metadata": {
        "id": "zl70QUxzr5TZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fp8 - needs more than free tier\n",
        "# !wget -q --show-progress https://huggingface.co/Comfy-Org/flux1-dev/resolve/main/flux1-dev-fp8.safetensors -P /content/ComfyUI/models/checkpoints"
      ],
      "metadata": {
        "id": "5JcA4RTtr0g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option 2 : [**gguf**](https://huggingface.co/city96/FLUX.1-dev-gguf) models.  "
      ],
      "metadata": {
        "id": "fcYI0H2QnITb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Git clone the [ComfyUI-GGUF](https://github.com/city96/ComfyUI-GGUF) repo and follow the instructions."
      ],
      "metadata": {
        "id": "rBW-zqXfzsYr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dvla7XiuVpN"
      },
      "outputs": [],
      "source": [
        "# %pip install --upgrade gguf\n",
        "# !rm -rf ./custom_nodes/ComfyUI-GGUF\n",
        "# !git clone https://github.com/city96/ComfyUI-GGUF /content/ComfyUI/custom_nodes/ComfyUI-GGUF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojrmju_XuVpQ"
      },
      "outputs": [],
      "source": [
        "# Download the one you need\n",
        "\n",
        "# flux1-dev\n",
        "# !wget -q --show-progress https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/flux1-dev-Q6_K.gguf -P /content/ComfyUI/models/unet\n",
        "\n",
        "# flux1-kontext-dev\n",
        "# !wget -q --show-progress https://huggingface.co/QuantStack/FLUX.1-Kontext-dev-GGUF/resolve/main/flux1-kontext-dev-Q6_K.gguf -P /content/ComfyUI/models/unet\n",
        "\n",
        "# flux1-krea-dev\n",
        "# !wget -q --show-progress https://huggingface.co/QuantStack/FLUX.1-Krea-dev-GGUF/resolve/main/flux1-krea-dev-Q6_K.gguf -P /content/ComfyUI/models/unet\n",
        "\n",
        "# flux1-schnell\n",
        "# !wget -q --show-progress https://huggingface.co/city96/FLUX.1-schnell-gguf/resolve/main/flux1-schnell-Q6_K.gguf -P /content/ComfyUI/models/unet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option 3 : [**Nunchaku**](https://nunchaku.tech/docs/ComfyUI-nunchaku/workflows/t2i.html#nunchaku-flux-1-dev-json) models - recommended"
      ],
      "metadata": {
        "id": "yDlSKb2rprjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "id": "GkNw42U8_F8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -q https://github.com/mit-han-lab/ComfyUI-nunchaku /content/ComfyUI/custom_nodes/nunchaku_nodes\n",
        "!pip install -q https://github.com/nunchaku-tech/nunchaku/releases/download/v0.3.2/nunchaku-0.3.2+torch2.8-cp311-cp311-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "Kxd_5jqxp7Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flux1-dev\n",
        "!wget -q --show-progress https://huggingface.co/nunchaku-tech/nunchaku-flux.1-dev/resolve/main/svdq-int4_r32-flux.1-dev.safetensors -P /content/ComfyUI/models/diffusion_models\n",
        "\n",
        "#flux1-krea-dev\n",
        "# !wget -q --show-progress https://huggingface.co/nunchaku-tech/nunchaku-flux.1-krea-dev/resolve/main/svdq-int4_r32-flux.1-krea-dev.safetensors -P /content/ComfyUI/models/diffusion_models\n",
        "\n",
        "#flux1-schnell\n",
        "# !wget -q --show-progress https://huggingface.co/nunchaku-tech/nunchaku-flux.1-schnell/resolve/main/svdq-int4_r32-flux.1-schnell.safetensors -P /content/ComfyUI/models/diffusion_models\n",
        "\n",
        "#flux1-kontext-dev\n",
        "# !wget -q --show-progress https://huggingface.co/nunchaku-tech/nunchaku-flux.1-kontext-dev/resolve/main/svdq-int4_r32-flux.1-kontext-dev.safetensors -P /content/ComfyUI/models/diffusion_models"
      ],
      "metadata": {
        "id": "WOTtjTUORfQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run ComfyUI with ngrok (recommended way)"
      ],
      "metadata": {
        "id": "8XPOPExF_tly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyngrok\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import subprocess, socket, time\n",
        "\n",
        "# Set ngrok token\n",
        "!ngrok config add-authtoken YOUR_TOKEN\n",
        "\n",
        "# Start ComfyUI in background\n",
        "subprocess.Popen([\"python\", \"/content/ComfyUI/main.py\", \"--dont-print-server\"])\n",
        "\n",
        "# Wait until port is open\n",
        "port = 8188\n",
        "while True:\n",
        "    try:\n",
        "        sock = socket.create_connection((\"127.0.0.1\", port), timeout=2)\n",
        "        sock.close()\n",
        "        print(\"‚úÖ ComfyUI server is running on port\", port)\n",
        "        break\n",
        "    except OSError:\n",
        "        print(\"‚è≥ Waiting for ComfyUI to start...\")\n",
        "        time.sleep(2)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(8188, bind_tls=True)\n",
        "print(\"üåê Public URL:\", public_url)\n"
      ],
      "metadata": {
        "id": "MTI7AYf1_ExB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !npm install -g localtunnel"
      ],
      "metadata": {
        "id": "47QdZgYl4EzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import subprocess\n",
        "# import threading\n",
        "# import time\n",
        "# import socket\n",
        "# import urllib.request\n",
        "# import sys\n",
        "\n",
        "# def wait_for_port(port):\n",
        "#     while True:\n",
        "#         time.sleep(0.5)\n",
        "#         sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "#         if sock.connect_ex(('127.0.0.1', port)) == 0:\n",
        "#             sock.close()\n",
        "#             break\n",
        "#         sock.close()\n",
        "\n",
        "#     print(\"\\nComfyUI finished loading, launching localtunnel...\\n\")\n",
        "#     print(\"Your public IP is:\",\n",
        "#           urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip())\n",
        "\n",
        "#     p = subprocess.Popen([\"lt\", \"--port\", str(port)], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "#     for line in iter(p.stdout.readline, ''):\n",
        "#         sys.stdout.write(line)\n",
        "#         sys.stdout.flush()\n",
        "\n",
        "# threading.Thread(target=wait_for_port, args=(8188,), daemon=True).start()\n",
        "\n",
        "# subprocess.run([\"python\", \"/content/ComfyUI/main.py\"])\n"
      ],
      "metadata": {
        "id": "l368kqI3-Bm5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gggggggggg"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}